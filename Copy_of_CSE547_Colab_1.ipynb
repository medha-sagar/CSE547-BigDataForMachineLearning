{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of CSE547 - Colab 1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/medha-sagar/CSE547-BigDataForMachineLearning/blob/master/Copy_of_CSE547_Colab_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPt5q27L5557",
        "colab_type": "text"
      },
      "source": [
        "# CSE 547 - Colab 1\n",
        "## Wordcount in Spark\n",
        "\n",
        "Adapted From Stanford CS246"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0-YhEpP_Ds-",
        "colab_type": "text"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zsj5WYpR9QId",
        "colab_type": "text"
      },
      "source": [
        "Let's setup Spark on your Colab environment.  Run the cell below!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-qHai2252mI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "edbf76f8-6514-457d-aeae-b044d9ab23b4"
      },
      "source": [
        "!pip install pyspark\n",
        "!pip install -U -q PyDrive\n",
        "!apt install openjdk-8-jdk-headless -qq\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/5a/271c416c1c2185b6cb0151b29a91fff6fcaed80173c8584ff6d20e46b465/pyspark-2.4.5.tar.gz (217.8MB)\n",
            "\u001b[K     |████████████████████████████████| 217.8MB 59kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 48.8MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-2.4.5-py2.py3-none-any.whl size=218257927 sha256=083078ce7a69a4f875cf6dce0bb6e4ec78cc2a0eaae62a6e009e5015e112529b\n",
            "  Stored in directory: /root/.cache/pip/wheels/bf/db/04/61d66a5939364e756eb1c1be4ec5bdce6e04047fc7929a3c3c\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.7 pyspark-2.4.5\n",
            "openjdk-8-jdk-headless is already the newest version (8u242-b08-0ubuntu3~18.04).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 25 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CJ71AKe91eh",
        "colab_type": "text"
      },
      "source": [
        "Now we authenticate a Google Drive client to download the file we will be processing in our Spark job.\n",
        "\n",
        "**Make sure to follow the interactive instructions.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5K93ABEy9Zlo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0orRvrc1-545",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "id='1SE6k_0YukzGd5wK-E4i6mG83nydlfvSa'\n",
        "downloaded = drive.CreateFile({'id': id})\n",
        "downloaded.GetContentFile('pg100.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwtlO4_m_LbQ",
        "colab_type": "text"
      },
      "source": [
        "If you executed the cells above, you should be able to see the file *pg100.txt* under the \"Files\" tab on the left panel."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRaF2A_j_nC7",
        "colab_type": "text"
      },
      "source": [
        "### Your task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebLNUxP0_8x3",
        "colab_type": "text"
      },
      "source": [
        "If you run successfully the setup stage, you are ready to work on the *pg100.txt* file which contains a copy of the complete works of Shakespeare.\n",
        "\n",
        "Write a Spark application which outputs the number of words that start with each letter. This means that for every letter we want to count the total number of (non-unique) words that start with a specific letter. In your implementation **ignore the letter case**, i.e., consider all words as lower case. Also, you can ignore all the words **starting** with a non-alphabetic character.\n",
        "\n",
        "For this task we ask you to the [**RDD MapReduce API**](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD) from spark (map, reduceByKey, flatMap, etc.) instead of **DataFrame API**. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xu-e7Ph2_ruG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pyspark\n",
        "from pyspark.sql import *\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark import SparkContext\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# create the Spark Session\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "\n",
        "# create the Spark Context\n",
        "sc = spark.sparkContext"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuAxGFPFB43Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "4110847b-692d-42d8-a7fc-65d5b1da3cd2"
      },
      "source": [
        "spark"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://549bf1e69e1c:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v2.4.5</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f1d5eff5b70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alXn6x5ylIZ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Shakespeare_Document = sc.textFile(\"pg100.txt\")\n",
        "words = Shakespeare_Document.flatMap(lambda line: line.split(\" \"))\n",
        "words_new = words.filter(lambda x: x != \"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCkoec5lvqab",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "84007e27-9a40-4297-ac8d-a5bd5baf22c1"
      },
      "source": [
        "words_new.take(16)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The',\n",
              " 'Project',\n",
              " 'Gutenberg',\n",
              " 'EBook',\n",
              " 'of',\n",
              " 'The',\n",
              " 'Complete',\n",
              " 'Works',\n",
              " 'of',\n",
              " 'William',\n",
              " 'Shakespeare,',\n",
              " 'by',\n",
              " 'William',\n",
              " 'Shakespeare',\n",
              " 'This',\n",
              " 'eBook']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIrXJyVNP2AI",
        "colab_type": "text"
      },
      "source": [
        "Once you obtained the desired results, **head over to Gradescope and submit your solution for this Colab**!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2EUwuEGnCqN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wordCounts = words_new.map(lambda word: (word[0].lower(), 1)) #.reduceByKey(lambda a,b:a +b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9E_pROHprUtE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "d5aded39-38e0-4941-c6a9-36e71ccc2502"
      },
      "source": [
        "wordCounts.take(16)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('t', 1),\n",
              " ('p', 1),\n",
              " ('g', 1),\n",
              " ('e', 1),\n",
              " ('o', 1),\n",
              " ('t', 1),\n",
              " ('c', 1),\n",
              " ('w', 1),\n",
              " ('o', 1),\n",
              " ('w', 1),\n",
              " ('s', 1),\n",
              " ('b', 1),\n",
              " ('w', 1),\n",
              " ('s', 1),\n",
              " ('t', 1),\n",
              " ('e', 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zx0xkGP3rWH7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "letterCount = wordCounts.reduceByKey(lambda a, b: a+b).sortBy(lambda r: -r[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKjANlMNuKcu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        },
        "outputId": "e3960322-5937-4702-ec7d-edb125aa2a6b"
      },
      "source": [
        "letterCount.take(100)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('t', 123602),\n",
              " ('a', 84836),\n",
              " ('s', 65705),\n",
              " ('i', 62167),\n",
              " ('h', 60563),\n",
              " ('w', 59597),\n",
              " ('m', 55676),\n",
              " ('b', 45455),\n",
              " ('o', 43494),\n",
              " ('f', 36814),\n",
              " ('c', 34567),\n",
              " ('d', 29713),\n",
              " ('l', 29569),\n",
              " ('p', 27759),\n",
              " ('n', 26759),\n",
              " ('y', 25855),\n",
              " ('g', 20782),\n",
              " ('e', 18697),\n",
              " ('r', 14265),\n",
              " ('k', 9418),\n",
              " ('u', 9170),\n",
              " ('v', 5728),\n",
              " (\"'\", 3804),\n",
              " ('j', 3339),\n",
              " ('q', 2377),\n",
              " ('[', 2073),\n",
              " ('(', 639),\n",
              " ('1', 458),\n",
              " ('\"', 356),\n",
              " ('<', 248),\n",
              " ('2', 95),\n",
              " ('z', 71),\n",
              " ('3', 59),\n",
              " ('.', 52),\n",
              " ('-', 52),\n",
              " ('4', 46),\n",
              " ('5', 35),\n",
              " ('9', 28),\n",
              " ('*', 24),\n",
              " ('6', 22),\n",
              " ('&', 21),\n",
              " ('7', 17),\n",
              " ('8', 15),\n",
              " ('x', 14),\n",
              " (']', 7),\n",
              " ('0', 6),\n",
              " ('#', 3),\n",
              " ('?', 2),\n",
              " ('}', 2),\n",
              " ('/', 2),\n",
              " ('_', 1),\n",
              " ('$', 1),\n",
              " (':', 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwhQG2gO1SIo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}